{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.12"},"colab":{"name":"Copy of BERT_upvote_predictor.ipynb","provenance":[{"file_id":"1Tfk_Nd-54WixT8tn-iK0kXfyvszMuDW3","timestamp":1620017356460}],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"alXHXUPcmpnN","executionInfo":{"status":"ok","timestamp":1620017431814,"user_tz":240,"elapsed":67089,"user":{"displayName":"Ryan Cooper","photoUrl":"","userId":"03930546846624815383"}},"outputId":"b35c2a76-66d8-41a1-ed9d-0b4c135864bf"},"source":["!wget https://www.dropbox.com/s/xq4vosn9xyn1dy1/grouped_data.pickle?dl=0 -O grouped_data.pickle"],"execution_count":1,"outputs":[{"output_type":"stream","text":["--2021-05-03 04:49:25--  https://www.dropbox.com/s/xq4vosn9xyn1dy1/grouped_data.pickle?dl=0\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.18, 2620:100:6027:18::a27d:4812\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.18|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/xq4vosn9xyn1dy1/grouped_data.pickle [following]\n","--2021-05-03 04:49:25--  https://www.dropbox.com/s/raw/xq4vosn9xyn1dy1/grouped_data.pickle\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc5e72d9c6fa30d8658dd63ce247.dl.dropboxusercontent.com/cd/0/inline/BNxHxA3pcLikxwHxuPR3-z1zg9sgrF2rNHx3wZvlYN2TRDEbLoSERgROvmGVULLX-rBb-q5RRwgEwlMnd4p9khSVAaX8lMHuUwrQMxda_rC4ySZ890yPq53GbvjwlHWKVHBEGb90H_5PgYKn7IvK7cyG/file# [following]\n","--2021-05-03 04:49:26--  https://uc5e72d9c6fa30d8658dd63ce247.dl.dropboxusercontent.com/cd/0/inline/BNxHxA3pcLikxwHxuPR3-z1zg9sgrF2rNHx3wZvlYN2TRDEbLoSERgROvmGVULLX-rBb-q5RRwgEwlMnd4p9khSVAaX8lMHuUwrQMxda_rC4ySZ890yPq53GbvjwlHWKVHBEGb90H_5PgYKn7IvK7cyG/file\n","Resolving uc5e72d9c6fa30d8658dd63ce247.dl.dropboxusercontent.com (uc5e72d9c6fa30d8658dd63ce247.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6027:15::a27d:480f\n","Connecting to uc5e72d9c6fa30d8658dd63ce247.dl.dropboxusercontent.com (uc5e72d9c6fa30d8658dd63ce247.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1740570798 (1.6G) [text/plain]\n","Saving to: â€˜grouped_data.pickleâ€™\n","\n","grouped_data.pickle 100%[===================>]   1.62G  28.1MB/s    in 64s     \n","\n","2021-05-03 04:50:31 (25.7 MB/s) - â€˜grouped_data.pickleâ€™ saved [1740570798/1740570798]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"luoxoSormhZ_","executionInfo":{"status":"ok","timestamp":1620017431815,"user_tz":240,"elapsed":67058,"user":{"displayName":"Ryan Cooper","photoUrl":"","userId":"03930546846624815383"}},"outputId":"7105a3e4-a05b-4a61-8df0-7666488898fd"},"source":["!nvidia-smi"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mon May  3 04:50:31 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0    23W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a7Bv9E4XmhaD","outputId":"e9b7e59b-4d2a-4408-a379-bfa2eaae313b"},"source":["import pickle\n","\n","import torch\n","!pip install transformers\n","from transformers import BertForSequenceClassification, BertTokenizerFast, Trainer, TrainingArguments\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","from tqdm.notebook import tqdm\n","from scipy import stats\n","import collections\n","\n","from google.colab import drive\n","\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.1MB 13.3MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 901kB 46.8MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 34.5MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Installing collected packages: sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IUQhbJSymhaE"},"source":["# load sample data\n","# format { post_id: [post, [comment1, comment2, ... ] }\n","\n","data_file_path = 'grouped_data.pickle'\n","\n","def load_data(file_path):\n","    posts_comments = []\n","    upvotes = []\n","    with open(file_path, 'rb') as f:\n","        data = pickle.load(f)\n","        for post_id, val in data.items():\n","            post = val[0]\n","            comms = val[1]\n","            for com in comms:\n","                try:\n","                    if len(post['title']) < 500 and len(com['body']) < 500 and com['body'] != '[deleted]' and com['body'] != '[removed]':\n","                        posts_comments.append((post['title'], com['body']))\n","                        upvotes.append(com['score'])\n","                except:\n","                    pass\n","                \n","    return posts_comments, upvotes\n","    \n","posts_comms, upvotes = load_data(data_file_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0abIlzherE9c"},"source":["upvotes = np.array(upvotes)\n","q1 = np.quantile(upvotes, 0.6)\n","\n","\n","classes = []\n","for label in upvotes:\n","  if label < q1:\n","    classes.append(0)\n","  else:\n","    classes.append(1)\n","\n","collections.Counter(classes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_euJJvl7mhaF"},"source":["# split text\n","train_texts, test_texts, train_labels, test_labels = train_test_split(posts_comms, classes, test_size=.05, train_size=.15, shuffle=True)\n","# train_texts, test_texts, train_labels, test_labels = train_test_split(posts_comms, upvotes, test_size=.1, train_size=.2, shuffle=True)\n","print(len(train_texts), len(train_labels), len(test_texts), len(test_labels))\n","\n","posts_comms = None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dzk2XpipmhaF"},"source":["# load tokenizer\n","tokenizer = BertTokenizerFast.from_pretrained('distilbert-base-cased', use_cache=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gsfdgwNgmhaF"},"source":["# tokenize train data\n","\n","train_post = []\n","train_comm = []\n","\n","for x in tqdm(train_texts):\n","    train_post.append(x[0])\n","    train_comm.append(x[1])\n","\n","train_texts = None\n","train_encodings = tokenizer(text=train_post, text_pair=train_comm, truncation=True, padding=True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aZNIJhn-mhaG"},"source":["# tokenize test data\n","\n","test_post = []\n","test_comm = []\n","\n","for x in tqdm(test_texts):\n","    test_post.append(x[0])\n","    test_comm.append(x[1])\n","\n","test_texts = None\n","\n","test_encodings = tokenizer(text=test_post, text_pair=test_comm, truncation=True, padding=True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Xq4Ue6MmhaH","executionInfo":{"status":"ok","timestamp":1620015312987,"user_tz":240,"elapsed":90466,"user":{"displayName":"Ryan Cooper","photoUrl":"","userId":"03930546846624815383"}},"outputId":"8dbef948-2772-4b59-c967-ec9a27fe19c4"},"source":["# load model\n","# model = BertForSequenceClassification.from_pretrained('distilbert-base-cased', num_labels=max(classes)+1)\n","model = BertForSequenceClassification.from_pretrained('/content/gdrive/My Drive/upvote_model_binary_0.15', num_labels=max(classes)+1)\n","model.train()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"_UV-sbjWmhaH"},"source":["# create dataset class and load encodings and associated labels to it\n","\n","class upvote_prediction_dataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","train_dataset = upvote_prediction_dataset(train_encodings, train_labels)\n","test_dataset = upvote_prediction_dataset(test_encodings, test_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"BnALj5i2mhaI","outputId":"89550d40-169d-4185-9ca4-2d1d7be67656"},"source":["training_args = TrainingArguments(\n","    output_dir='./results',          # output directory\n","    num_train_epochs=2,              # total number of training epochs\n","    per_device_train_batch_size=16,  # batch size per device during training\n","    per_device_eval_batch_size=16,   # batch size for evaluation\n","    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n","    weight_decay=0.01,               # strength of weight decay\n","    logging_dir='./logs',            # directory for storing logs\n","    logging_steps=10,\n",")\n","\n","trainer = Trainer(\n","    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n","    args=training_args,                  # training arguments, defined above\n","    train_dataset=train_dataset,         # training dataset\n","    eval_dataset=test_dataset             # evaluation dataset\n",")\n","\n","trainer.train()\n","\n","trainer.save_model()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='3324' max='26314' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 3324/26314 33:52 < 3:54:25, 1.63 it/s, Epoch 0.25/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.687200</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.696600</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.686000</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.692700</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.701600</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.686600</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.684600</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.696400</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.690900</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.680400</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.692200</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.700900</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.706000</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.698300</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.688600</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.705100</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.688000</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.702400</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.688900</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.704700</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.693200</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.696400</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.698100</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.691000</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.693900</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.702100</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.688500</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.699000</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.701400</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.693700</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.697300</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.692600</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.684600</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.697400</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.700900</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.698900</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.698800</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.695600</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.688600</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.714600</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.697100</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.698700</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.699200</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.693800</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.694200</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.706200</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.689600</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.698000</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.693600</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.701100</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.697900</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.697200</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.702400</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.704000</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.695300</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.707100</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.695700</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.695700</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.695200</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.711900</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.678000</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.706200</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.690200</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.696200</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.694100</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.694700</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.698700</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.704700</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.686100</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.706900</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.698200</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.682900</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.722000</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.700800</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.688200</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.702400</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.696100</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.688700</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.695000</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.701800</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.696500</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.704800</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.705600</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.689900</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.697800</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.691600</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.698900</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.712800</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.710200</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.704300</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.696800</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.691800</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.701600</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.697100</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.695600</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.691800</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.688700</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.706300</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.691600</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.706700</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.692200</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.691800</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.702300</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.691900</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.694900</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.700700</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.709300</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.690800</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.710400</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.696900</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.697900</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.697700</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.693600</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.692700</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.708700</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.702000</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.697900</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.701100</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.698100</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.690600</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.707700</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.693300</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.702200</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.692100</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.701600</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.698500</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.694300</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.701400</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.699000</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.694600</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.697300</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.694300</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.688000</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.686100</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.698700</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.698300</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.691900</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.705600</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.694100</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.705900</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.707500</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.695000</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.698400</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.690400</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.685600</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.704400</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.686500</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.692700</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.694700</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.703300</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.692500</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.706300</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.689500</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.717500</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.695300</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.693800</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.702900</td>\n","    </tr>\n","    <tr>\n","      <td>1580</td>\n","      <td>0.691700</td>\n","    </tr>\n","    <tr>\n","      <td>1590</td>\n","      <td>0.703400</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.690600</td>\n","    </tr>\n","    <tr>\n","      <td>1610</td>\n","      <td>0.697700</td>\n","    </tr>\n","    <tr>\n","      <td>1620</td>\n","      <td>0.713500</td>\n","    </tr>\n","    <tr>\n","      <td>1630</td>\n","      <td>0.699700</td>\n","    </tr>\n","    <tr>\n","      <td>1640</td>\n","      <td>0.706900</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>0.691400</td>\n","    </tr>\n","    <tr>\n","      <td>1660</td>\n","      <td>0.698200</td>\n","    </tr>\n","    <tr>\n","      <td>1670</td>\n","      <td>0.699400</td>\n","    </tr>\n","    <tr>\n","      <td>1680</td>\n","      <td>0.693500</td>\n","    </tr>\n","    <tr>\n","      <td>1690</td>\n","      <td>0.700400</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.692200</td>\n","    </tr>\n","    <tr>\n","      <td>1710</td>\n","      <td>0.683600</td>\n","    </tr>\n","    <tr>\n","      <td>1720</td>\n","      <td>0.680300</td>\n","    </tr>\n","    <tr>\n","      <td>1730</td>\n","      <td>0.712400</td>\n","    </tr>\n","    <tr>\n","      <td>1740</td>\n","      <td>0.715700</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.700300</td>\n","    </tr>\n","    <tr>\n","      <td>1760</td>\n","      <td>0.698800</td>\n","    </tr>\n","    <tr>\n","      <td>1770</td>\n","      <td>0.683500</td>\n","    </tr>\n","    <tr>\n","      <td>1780</td>\n","      <td>0.698900</td>\n","    </tr>\n","    <tr>\n","      <td>1790</td>\n","      <td>0.693700</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.700100</td>\n","    </tr>\n","    <tr>\n","      <td>1810</td>\n","      <td>0.698300</td>\n","    </tr>\n","    <tr>\n","      <td>1820</td>\n","      <td>0.690000</td>\n","    </tr>\n","    <tr>\n","      <td>1830</td>\n","      <td>0.700300</td>\n","    </tr>\n","    <tr>\n","      <td>1840</td>\n","      <td>0.705800</td>\n","    </tr>\n","    <tr>\n","      <td>1850</td>\n","      <td>0.708100</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.694200</td>\n","    </tr>\n","    <tr>\n","      <td>1870</td>\n","      <td>0.690500</td>\n","    </tr>\n","    <tr>\n","      <td>1880</td>\n","      <td>0.702300</td>\n","    </tr>\n","    <tr>\n","      <td>1890</td>\n","      <td>0.701500</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.704000</td>\n","    </tr>\n","    <tr>\n","      <td>1910</td>\n","      <td>0.685600</td>\n","    </tr>\n","    <tr>\n","      <td>1920</td>\n","      <td>0.708000</td>\n","    </tr>\n","    <tr>\n","      <td>1930</td>\n","      <td>0.688800</td>\n","    </tr>\n","    <tr>\n","      <td>1940</td>\n","      <td>0.680900</td>\n","    </tr>\n","    <tr>\n","      <td>1950</td>\n","      <td>0.721900</td>\n","    </tr>\n","    <tr>\n","      <td>1960</td>\n","      <td>0.696300</td>\n","    </tr>\n","    <tr>\n","      <td>1970</td>\n","      <td>0.697800</td>\n","    </tr>\n","    <tr>\n","      <td>1980</td>\n","      <td>0.703300</td>\n","    </tr>\n","    <tr>\n","      <td>1990</td>\n","      <td>0.697200</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.698500</td>\n","    </tr>\n","    <tr>\n","      <td>2010</td>\n","      <td>0.691100</td>\n","    </tr>\n","    <tr>\n","      <td>2020</td>\n","      <td>0.694900</td>\n","    </tr>\n","    <tr>\n","      <td>2030</td>\n","      <td>0.688900</td>\n","    </tr>\n","    <tr>\n","      <td>2040</td>\n","      <td>0.702600</td>\n","    </tr>\n","    <tr>\n","      <td>2050</td>\n","      <td>0.693800</td>\n","    </tr>\n","    <tr>\n","      <td>2060</td>\n","      <td>0.706100</td>\n","    </tr>\n","    <tr>\n","      <td>2070</td>\n","      <td>0.700900</td>\n","    </tr>\n","    <tr>\n","      <td>2080</td>\n","      <td>0.692400</td>\n","    </tr>\n","    <tr>\n","      <td>2090</td>\n","      <td>0.693700</td>\n","    </tr>\n","    <tr>\n","      <td>2100</td>\n","      <td>0.694800</td>\n","    </tr>\n","    <tr>\n","      <td>2110</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>2120</td>\n","      <td>0.704900</td>\n","    </tr>\n","    <tr>\n","      <td>2130</td>\n","      <td>0.692400</td>\n","    </tr>\n","    <tr>\n","      <td>2140</td>\n","      <td>0.699100</td>\n","    </tr>\n","    <tr>\n","      <td>2150</td>\n","      <td>0.697100</td>\n","    </tr>\n","    <tr>\n","      <td>2160</td>\n","      <td>0.709700</td>\n","    </tr>\n","    <tr>\n","      <td>2170</td>\n","      <td>0.696700</td>\n","    </tr>\n","    <tr>\n","      <td>2180</td>\n","      <td>0.692600</td>\n","    </tr>\n","    <tr>\n","      <td>2190</td>\n","      <td>0.702700</td>\n","    </tr>\n","    <tr>\n","      <td>2200</td>\n","      <td>0.692300</td>\n","    </tr>\n","    <tr>\n","      <td>2210</td>\n","      <td>0.699400</td>\n","    </tr>\n","    <tr>\n","      <td>2220</td>\n","      <td>0.696500</td>\n","    </tr>\n","    <tr>\n","      <td>2230</td>\n","      <td>0.688700</td>\n","    </tr>\n","    <tr>\n","      <td>2240</td>\n","      <td>0.702200</td>\n","    </tr>\n","    <tr>\n","      <td>2250</td>\n","      <td>0.692800</td>\n","    </tr>\n","    <tr>\n","      <td>2260</td>\n","      <td>0.696400</td>\n","    </tr>\n","    <tr>\n","      <td>2270</td>\n","      <td>0.708900</td>\n","    </tr>\n","    <tr>\n","      <td>2280</td>\n","      <td>0.704300</td>\n","    </tr>\n","    <tr>\n","      <td>2290</td>\n","      <td>0.699400</td>\n","    </tr>\n","    <tr>\n","      <td>2300</td>\n","      <td>0.690800</td>\n","    </tr>\n","    <tr>\n","      <td>2310</td>\n","      <td>0.696100</td>\n","    </tr>\n","    <tr>\n","      <td>2320</td>\n","      <td>0.704000</td>\n","    </tr>\n","    <tr>\n","      <td>2330</td>\n","      <td>0.700700</td>\n","    </tr>\n","    <tr>\n","      <td>2340</td>\n","      <td>0.700200</td>\n","    </tr>\n","    <tr>\n","      <td>2350</td>\n","      <td>0.710600</td>\n","    </tr>\n","    <tr>\n","      <td>2360</td>\n","      <td>0.699800</td>\n","    </tr>\n","    <tr>\n","      <td>2370</td>\n","      <td>0.694600</td>\n","    </tr>\n","    <tr>\n","      <td>2380</td>\n","      <td>0.692700</td>\n","    </tr>\n","    <tr>\n","      <td>2390</td>\n","      <td>0.714700</td>\n","    </tr>\n","    <tr>\n","      <td>2400</td>\n","      <td>0.710700</td>\n","    </tr>\n","    <tr>\n","      <td>2410</td>\n","      <td>0.685800</td>\n","    </tr>\n","    <tr>\n","      <td>2420</td>\n","      <td>0.710900</td>\n","    </tr>\n","    <tr>\n","      <td>2430</td>\n","      <td>0.714600</td>\n","    </tr>\n","    <tr>\n","      <td>2440</td>\n","      <td>0.697600</td>\n","    </tr>\n","    <tr>\n","      <td>2450</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>2460</td>\n","      <td>0.692300</td>\n","    </tr>\n","    <tr>\n","      <td>2470</td>\n","      <td>0.701800</td>\n","    </tr>\n","    <tr>\n","      <td>2480</td>\n","      <td>0.688700</td>\n","    </tr>\n","    <tr>\n","      <td>2490</td>\n","      <td>0.686800</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.699400</td>\n","    </tr>\n","    <tr>\n","      <td>2510</td>\n","      <td>0.700600</td>\n","    </tr>\n","    <tr>\n","      <td>2520</td>\n","      <td>0.701700</td>\n","    </tr>\n","    <tr>\n","      <td>2530</td>\n","      <td>0.696100</td>\n","    </tr>\n","    <tr>\n","      <td>2540</td>\n","      <td>0.693400</td>\n","    </tr>\n","    <tr>\n","      <td>2550</td>\n","      <td>0.684400</td>\n","    </tr>\n","    <tr>\n","      <td>2560</td>\n","      <td>0.695200</td>\n","    </tr>\n","    <tr>\n","      <td>2570</td>\n","      <td>0.696100</td>\n","    </tr>\n","    <tr>\n","      <td>2580</td>\n","      <td>0.708000</td>\n","    </tr>\n","    <tr>\n","      <td>2590</td>\n","      <td>0.686900</td>\n","    </tr>\n","    <tr>\n","      <td>2600</td>\n","      <td>0.729000</td>\n","    </tr>\n","    <tr>\n","      <td>2610</td>\n","      <td>0.698600</td>\n","    </tr>\n","    <tr>\n","      <td>2620</td>\n","      <td>0.694400</td>\n","    </tr>\n","    <tr>\n","      <td>2630</td>\n","      <td>0.695700</td>\n","    </tr>\n","    <tr>\n","      <td>2640</td>\n","      <td>0.690900</td>\n","    </tr>\n","    <tr>\n","      <td>2650</td>\n","      <td>0.695000</td>\n","    </tr>\n","    <tr>\n","      <td>2660</td>\n","      <td>0.698200</td>\n","    </tr>\n","    <tr>\n","      <td>2670</td>\n","      <td>0.695400</td>\n","    </tr>\n","    <tr>\n","      <td>2680</td>\n","      <td>0.701500</td>\n","    </tr>\n","    <tr>\n","      <td>2690</td>\n","      <td>0.695900</td>\n","    </tr>\n","    <tr>\n","      <td>2700</td>\n","      <td>0.693700</td>\n","    </tr>\n","    <tr>\n","      <td>2710</td>\n","      <td>0.712100</td>\n","    </tr>\n","    <tr>\n","      <td>2720</td>\n","      <td>0.693100</td>\n","    </tr>\n","    <tr>\n","      <td>2730</td>\n","      <td>0.695500</td>\n","    </tr>\n","    <tr>\n","      <td>2740</td>\n","      <td>0.704900</td>\n","    </tr>\n","    <tr>\n","      <td>2750</td>\n","      <td>0.696500</td>\n","    </tr>\n","    <tr>\n","      <td>2760</td>\n","      <td>0.693500</td>\n","    </tr>\n","    <tr>\n","      <td>2770</td>\n","      <td>0.705100</td>\n","    </tr>\n","    <tr>\n","      <td>2780</td>\n","      <td>0.689400</td>\n","    </tr>\n","    <tr>\n","      <td>2790</td>\n","      <td>0.704800</td>\n","    </tr>\n","    <tr>\n","      <td>2800</td>\n","      <td>0.706200</td>\n","    </tr>\n","    <tr>\n","      <td>2810</td>\n","      <td>0.700600</td>\n","    </tr>\n","    <tr>\n","      <td>2820</td>\n","      <td>0.705100</td>\n","    </tr>\n","    <tr>\n","      <td>2830</td>\n","      <td>0.710800</td>\n","    </tr>\n","    <tr>\n","      <td>2840</td>\n","      <td>0.698900</td>\n","    </tr>\n","    <tr>\n","      <td>2850</td>\n","      <td>0.690300</td>\n","    </tr>\n","    <tr>\n","      <td>2860</td>\n","      <td>0.690400</td>\n","    </tr>\n","    <tr>\n","      <td>2870</td>\n","      <td>0.700600</td>\n","    </tr>\n","    <tr>\n","      <td>2880</td>\n","      <td>0.706900</td>\n","    </tr>\n","    <tr>\n","      <td>2890</td>\n","      <td>0.686100</td>\n","    </tr>\n","    <tr>\n","      <td>2900</td>\n","      <td>0.704200</td>\n","    </tr>\n","    <tr>\n","      <td>2910</td>\n","      <td>0.696500</td>\n","    </tr>\n","    <tr>\n","      <td>2920</td>\n","      <td>0.686000</td>\n","    </tr>\n","    <tr>\n","      <td>2930</td>\n","      <td>0.693900</td>\n","    </tr>\n","    <tr>\n","      <td>2940</td>\n","      <td>0.690000</td>\n","    </tr>\n","    <tr>\n","      <td>2950</td>\n","      <td>0.689400</td>\n","    </tr>\n","    <tr>\n","      <td>2960</td>\n","      <td>0.702900</td>\n","    </tr>\n","    <tr>\n","      <td>2970</td>\n","      <td>0.699200</td>\n","    </tr>\n","    <tr>\n","      <td>2980</td>\n","      <td>0.699200</td>\n","    </tr>\n","    <tr>\n","      <td>2990</td>\n","      <td>0.691700</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.700100</td>\n","    </tr>\n","    <tr>\n","      <td>3010</td>\n","      <td>0.705800</td>\n","    </tr>\n","    <tr>\n","      <td>3020</td>\n","      <td>0.698100</td>\n","    </tr>\n","    <tr>\n","      <td>3030</td>\n","      <td>0.705600</td>\n","    </tr>\n","    <tr>\n","      <td>3040</td>\n","      <td>0.693000</td>\n","    </tr>\n","    <tr>\n","      <td>3050</td>\n","      <td>0.705000</td>\n","    </tr>\n","    <tr>\n","      <td>3060</td>\n","      <td>0.686400</td>\n","    </tr>\n","    <tr>\n","      <td>3070</td>\n","      <td>0.703700</td>\n","    </tr>\n","    <tr>\n","      <td>3080</td>\n","      <td>0.690700</td>\n","    </tr>\n","    <tr>\n","      <td>3090</td>\n","      <td>0.697300</td>\n","    </tr>\n","    <tr>\n","      <td>3100</td>\n","      <td>0.698500</td>\n","    </tr>\n","    <tr>\n","      <td>3110</td>\n","      <td>0.689000</td>\n","    </tr>\n","    <tr>\n","      <td>3120</td>\n","      <td>0.692800</td>\n","    </tr>\n","    <tr>\n","      <td>3130</td>\n","      <td>0.705800</td>\n","    </tr>\n","    <tr>\n","      <td>3140</td>\n","      <td>0.692700</td>\n","    </tr>\n","    <tr>\n","      <td>3150</td>\n","      <td>0.699100</td>\n","    </tr>\n","    <tr>\n","      <td>3160</td>\n","      <td>0.689700</td>\n","    </tr>\n","    <tr>\n","      <td>3170</td>\n","      <td>0.692100</td>\n","    </tr>\n","    <tr>\n","      <td>3180</td>\n","      <td>0.692000</td>\n","    </tr>\n","    <tr>\n","      <td>3190</td>\n","      <td>0.695500</td>\n","    </tr>\n","    <tr>\n","      <td>3200</td>\n","      <td>0.699300</td>\n","    </tr>\n","    <tr>\n","      <td>3210</td>\n","      <td>0.711200</td>\n","    </tr>\n","    <tr>\n","      <td>3220</td>\n","      <td>0.706400</td>\n","    </tr>\n","    <tr>\n","      <td>3230</td>\n","      <td>0.698700</td>\n","    </tr>\n","    <tr>\n","      <td>3240</td>\n","      <td>0.696400</td>\n","    </tr>\n","    <tr>\n","      <td>3250</td>\n","      <td>0.698400</td>\n","    </tr>\n","    <tr>\n","      <td>3260</td>\n","      <td>0.693100</td>\n","    </tr>\n","    <tr>\n","      <td>3270</td>\n","      <td>0.701300</td>\n","    </tr>\n","    <tr>\n","      <td>3280</td>\n","      <td>0.693400</td>\n","    </tr>\n","    <tr>\n","      <td>3290</td>\n","      <td>0.716000</td>\n","    </tr>\n","    <tr>\n","      <td>3300</td>\n","      <td>0.702800</td>\n","    </tr>\n","    <tr>\n","      <td>3310</td>\n","      <td>0.697500</td>\n","    </tr>\n","    <tr>\n","      <td>3320</td>\n","      <td>0.694100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Huwqu4Z46NCa"},"source":["trainer.save_model('/content/gdrive/My Drive/upvote_model_binary_0.30')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LGjandOpN-4X"},"source":[""],"execution_count":null,"outputs":[]}]}